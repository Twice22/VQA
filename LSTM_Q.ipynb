{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# others libraries\n",
    "import spacy\n",
    "import numpy as np\n",
    "import collections\n",
    "import operator\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters of the neural_network\n",
    "num_hidden_units_mlp = 1024\n",
    "num_hidden_units_lstm = 512\n",
    "img_dim = 4096\n",
    "word_vec_dim = 300\n",
    "max_len = 30\n",
    "nb_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(LSTM(units = num_hidden_units_lstm, activation='tanh', \n",
    "#               return_sequences=True, input_shape=(max_len, word_vec_dim)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(num_hidden_units_lstm, activation='tanh', input_shape=(max_len, word_vec_dim)))\n",
    "model.add(Dense(nb_classes, kernel_initializer='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 512)               1665024   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              513000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 2,178,024.0\n",
      "Trainable params: 2,178,024.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: need to debug the installation of keras to be able to see the model in a better way\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='LSTM_Q.png')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loaded word2vec embeddings from spacy\n",
    "word_embeddings = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_features(question):\n",
    "    \"\"\"\n",
    "        Returns the embeddings (word2vec) of all the words of the question\n",
    "        :param question string that represents the question\n",
    "    \"\"\"\n",
    "    tokens = word_embeddings(question)\n",
    "    features = np.zeros((len(tokens), 300))\n",
    "       \n",
    "    for i, token in enumerate(tokens):\n",
    "        features[i, :] = token.vector\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_question = json.load(open('Questions/v2_OpenEnded_mscoco_train2014_questions.json'))\n",
    "data_answer = json.load(open('Annotations/v2_mscoco_train2014_annotations.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data_question, data_answer):\n",
    "    data_ans = data_answer['annotations']\n",
    "    data_ques = data_question['questions']    \n",
    "    \n",
    "    d = collections.defaultdict(dict)\n",
    "    \n",
    "    questions = []\n",
    "    questions_len = []\n",
    "    \n",
    "    answers = []\n",
    "    images_id = []\n",
    "    questions_id = []\n",
    "    \n",
    "    for i in range(len(data_ques)):\n",
    "        q_id = data_ques[i]['question_id']\n",
    "        img_id = data_ques[i]['image_id']\n",
    "        question = data_ques[i]['question']\n",
    "        d[img_id][q_id] = [question,len(question.split()) + 1] # add one for the interrogation point\n",
    "        \n",
    "    for i in range(len(data_ans)):\n",
    "        img_id = data_ans[i]['image_id']\n",
    "        q_id = data_ans[i]['question_id']\n",
    "        \n",
    "        questions_id.append(q_id)\n",
    "        images_id.append(img_id)\n",
    "        answers.append(data_ans[i]['multiple_choice_answer'])\n",
    "        questions.append(d[img_id][q_id][0])\n",
    "        questions_len.append(d[img_id][q_id][1])\n",
    "    \n",
    "    return images_id, questions_id, answers, questions, questions_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: don't need questions_len or maybe need to improve the training...\n",
    "# return 5 arrays containing image_id, questions_id, answers (words), questions (sentences), questions_len (nb words in question)\n",
    "images_id, questions_id, answers, questions, questions_len = preprocess_data(data_question, data_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topKFrequentAnswer(data_q, data_a, K=1000):\n",
    "    \"\"\"\n",
    "        Returns the image_id, question_id, answers, questions and questions_len whose answers are in the K most frequent Answer\n",
    "        param: data_q json file of questions\n",
    "        param: data_a json file of answers\n",
    "        param: K number of most frequent answers (K = 1000 by default as in the paper they use K = 1000)\n",
    "    \"\"\"\n",
    "    \n",
    "    images_id, questions_id, answers, questions, questions_len = preprocess_data(data_q, data_a)\n",
    "    \n",
    "    d = dict()\n",
    "    \n",
    "    # retrieve the top K answers\n",
    "    for answer in answers:\n",
    "        d[answer] = 0 if answer not in d else d[answer] + 1\n",
    "    \n",
    "    topKAnswers = np.array(sorted(d.items(), key=operator.itemgetter(1), reverse=True)[:K])[:, 0]\n",
    "    \n",
    "    # keep only question_id, image_id, questions, questions_len associated with the topKAnswers\n",
    "    new_images_id = []\n",
    "    new_questions = []\n",
    "    new_answers = []\n",
    "    new_questions_len = []\n",
    "    new_questions_id = []\n",
    "    \n",
    "    \n",
    "    for a, q, q_id, q_len, img in zip(answers, questions, questions_id, questions_len, images_id):\n",
    "        if a in topKAnswers:\n",
    "            new_images_id.append(img)\n",
    "            new_questions.append(q)\n",
    "            new_questions_len.append(q_len)\n",
    "            new_answers.append(a)\n",
    "            new_questions_id.append(q_id)\n",
    "        \n",
    "    \n",
    "    return new_images_id, questions_id, new_answers, new_questions, new_questions_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_images_id, K_questions_id, K_answers, K_questions, K_questions_len = topKFrequentAnswer(data_question, data_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[458752, 458752, 458752, 458752, 262146, 262146, 262146, 524291, 524291, 524291]\n",
      "[458752000, 458752001, 458752002, 458752003, 262146000, 262146001, 262146002, 524291000, 524291001, 524291002]\n",
      "['net', 'pitcher', 'orange', 'yes', 'white', 'skiing', 'red', 'frisbee', 'yes', 'frisbee']\n",
      "['What is this photo taken looking through?', 'What position is this man playing?', 'What color is the players shirt?', 'Is this man a professional baseball player?', 'What color is the snow?', 'What is the person doing?', 'What color is the persons headwear?', \"What is in the person's hand?\", 'Is the dog waiting?', 'Is the dog looking at a tennis ball or frisbee?']\n",
      "[8, 7, 7, 8, 6, 6, 7, 7, 5, 11]\n"
     ]
    }
   ],
   "source": [
    "print(K_images_id[:10])\n",
    "print(K_questions_id[:10])\n",
    "print(K_answers[:10])\n",
    "print(K_questions[:10])\n",
    "print(K_questions_len[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to iterates using batches (from stackoverflow)\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# atot stands for answers to tensors (transform batch of answers to one-hot encoding)\n",
    "def atot(answers, encoder):\n",
    "    y = encoder.transform(answers)\n",
    "    nb_classes = encoder.classes_.shape[0]\n",
    "    Y = np_utils.to_categorical(y, nb_classes)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qtot stands for questions to tensors (transform batch of questions to tensors using word2vec embeddings)\n",
    "def qtot(questions, max_len):\n",
    "    res = np.zeros((len(questions), max_len, 300)) # word2vec dimension = 300\n",
    "    \n",
    "    for i, question in enumerate(questions):\n",
    "        q_word2vec = question_features(question)\n",
    "        nb_words, _ = q_word2vec.shape\n",
    "        res[i,:nb_words] = q_word2vec\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "# avoid 'Set changed size during iteration' bug\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from spacy.en import English\n",
    "nlp = English()\n",
    "\n",
    "# number of epochs that you would like to use to train the model.\n",
    "epochs = 20\n",
    "\n",
    "# batch size\n",
    "batch_size = 128\n",
    "\n",
    "# save the best weights during training.\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "# train the model\n",
    "# to avoid memory overload we cannot use the below line with embeddings in memory (too big),\n",
    "# so we need to iterates using batch !\n",
    "# model.fit(X_train, y_train, \n",
    "#          validation_data=(X_val, y_val),\n",
    "#          epochs=epochs, batch_size=128, callbacks=[checkpointer, TQDMNotebookCallback()], verbose=0)\n",
    "\n",
    "labelencoder = preprocessing.LabelEncoder()\n",
    "labelencoder.fit(K_answers)\n",
    "nb_classes = len(list(labelencoder.classes_))\n",
    "\n",
    "f = lambda a: len(a.split())\n",
    "\n",
    "# TODO: maybe add validation data and train on both train + validation (paper did that)\n",
    "# 388158 questions to treat by epoch !\n",
    "\n",
    "for k in tqdm(range(epochs), desc=\"Simulating {}\".format(\"...\")):\n",
    "    i = 0\n",
    "    # use batch of image, answer and image to train the network\n",
    "    for batch_q, batch_img, batch_a in zip(batch(K_questions, batch_size), batch(K_images_id, batch_size), batch(K_answers, batch_size)):\n",
    "        \n",
    "        print(i)\n",
    "        i += batch_size\n",
    "        ## transform data to vectors/classes number\n",
    "        \n",
    "        # max number of words in a sentence by batch\n",
    "        # max_words = f(max(batch_q, key = f)) + 1 # +1 to account for the '?'\n",
    "        \n",
    "        # qtot stands for questions to tensor\n",
    "        X_batch = qtot(batch_q, 30)\n",
    "        \n",
    "        # atot stand for answers to tensor\n",
    "        Y_batch = atot(batch_a, labelencoder)\n",
    "        \n",
    "        # train the model\n",
    "        loss = model.train_on_batch(X_batch, Y_batch)\n",
    "    \n",
    "    # save weights at each epoch\n",
    "    model.save_weights('LSTM_Q/LSTM_Q_epoch_{:02d}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on single question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = json.load(open('Questions/v2_OpenEnded_mscoco_test-dev2015_questions.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"question: \", data_test['questions'][25]['question'])\n",
    "question_feat = qtot([data_test['questions'][25]['question']], 30)\n",
    "question_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(question_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelencoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate the json dictionary for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_q = []\n",
    "i = 0\n",
    "for q in data_test['questions']:\n",
    "    d = {}\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    # 30 = max_words in a question\n",
    "    question_feat = qtot([q['question']], 30)\n",
    "    d['answer'] = labelencoder.inverse_transform(np.argmax(model.predict(question_feat)))\n",
    "    d['question_id'] = q['question_id']\n",
    "    lstm_q.append(d)\n",
    "    i += 1\n",
    "\n",
    "with open('lstm_q.json', 'w') as outfile:\n",
    "    json.dump(lstm_q, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
